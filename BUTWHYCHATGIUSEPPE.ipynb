{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Youssef-Rachad/RL-Speech-Disfluency/blob/main/BUTWHYCHATGIUSEPPE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ml_things transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBzhjH2koPT8",
        "outputId": "eb2d24e2-6eab-43ea-d688-7bde3ef670da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io, os, torch, pandas\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from ml_things import plot_dict, plot_confusion_matrix, fix_text\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from transformers import (set_seed,\n",
        "                          TrainingArguments,\n",
        "                          Trainer,\n",
        "                          GPT2Config,\n",
        "                          GPT2Tokenizer,\n",
        "                          AdamW,\n",
        "                          get_linear_schedule_with_warmup,\n",
        "                          GPT2ForSequenceClassification)\n",
        "\n",
        "set_seed(359)\n",
        "epochs = 4\n",
        "\n",
        "batch_size = 32\n",
        "max_length = 60\n",
        "model_name_or_path = 'gpt2'\n",
        "labels_ids = [0, 1, 2, 3, 4, 5, 6]\n",
        "# labels_ids = {1: 1, 2: 2,  3: 3,  4: 4,  5: 5,  6: 6,  7: 7}\n",
        "n_labels = 7"
      ],
      "metadata": {
        "id": "Knyd1Z83FbOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TranscriptDataset(Dataset):\n",
        "    def __init__(self, path, ratings_file, use_tokenizer):\n",
        "        if not os.path.isdir(path):\n",
        "            raise ValueError(\"Woopeedoopee, \"+path+\" is poopoo\")\n",
        "\n",
        "        ratings = pandas.read_csv(ratings_file)\n",
        "        self.texts = []\n",
        "        self.labels = []\n",
        "\n",
        "        for file_name in tqdm(os.listdir(path), desc=f\"transcript file\"):\n",
        "            file_path = os.path.join(path, file_name)\n",
        "            content = fix_text(io.open(file_path, mode='r', encoding='utf-8').read())\n",
        "            for rating in ratings[ratings['video_id'] == file_name[-15: -4]]['Rating']:\n",
        "                self.texts.append(content)\n",
        "                self.labels.append(rating - 1)\n",
        "\n",
        "        self.n_examples = len(self.labels)\n",
        "        return\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_examples\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return {\n",
        "                'transcript': self.texts[item],\n",
        "                'rating': self.labels[item]\n",
        "                }\n",
        "\n",
        "class GPT2ClassificationCollator(object):\n",
        "    def __init__(self, use_tokenizer, labels_encoder, max_sequence_len=None):\n",
        "        self.use_tokenizer = use_tokenizer\n",
        "        self.max_sequence_len = use_tokenizer.model_max_length if max_sequence_len is None else max_sequence_len\n",
        "        self.labels_encoder = labels_encoder\n",
        "\n",
        "        return\n",
        "\n",
        "    def __call__(self, sequences):\n",
        "        texts  = [sequence['transcript'] for sequence in sequences]\n",
        "        labels = [sequence['rating'] for sequence in sequences]\n",
        "        inputs = [label - 1 for label in labels]\n",
        "        inputs = self.use_tokenizer(text=texts, return_tensors='pt', padding=True, truncation=True, max_length=self.max_sequence_len)\n",
        "        inputs.update({'labels': torch.tensor(labels)})\n",
        "        return inputs"
      ],
      "metadata": {
        "id": "W_RE6Jt0F2o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, optimizer_, scheduler_, device_):\n",
        "    global model\n",
        "    predictions_labels = []\n",
        "    true_labels = []\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
        "        true_labels += batch['labels'].numpy().flatten().tolist() # labels are ratings\n",
        "        batch = {k:v.type(torch.long) for k, v in batch.items()}\n",
        "        model.zero_grad()\n",
        "        outputs = model(**batch)\n",
        "        loss, logits = outputs[:2]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer_.step()\n",
        "        scheduler_.step()\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        predictions_labels += logits.argmax(axis=1).flatten().tolist()\n",
        "    avg_epoch_loss = total_loss / len(dataloader)\n",
        "    return true_labels, predictions_labels, avg_epoch_loss\n",
        "\n",
        "def validation(dataloader, device_):\n",
        "    global model\n",
        "    predictions_labels = []\n",
        "    true_labels = []\n",
        "    total_loss = 0\n",
        "    model.eval()\n",
        "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
        "        true_labels += [int(i) for i in batch['labels'].numpy().flatten().tolist()]\n",
        "        batch = {k:v.type(torch.long) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "            loss, logits = outputs[:2]\n",
        "            total_loss += loss.item()\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            predictions_labels += logits.argmax(axis=1).flatten().tolist()\n",
        "    avg_epoch_loss = total_loss / len(dataloader)\n",
        "    return true_labels, predictions_labels, avg_epoch_loss"
      ],
      "metadata": {
        "id": "2Mh1FQq7FzYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model configuration.\n",
        "print('Loading configuraiton...')\n",
        "model_config = GPT2Config.from_pretrained(pretrained_model_name_or_path=model_name_or_path, num_labels=n_labels)\n",
        "\n",
        "# Get model's tokenizer.\n",
        "print('Loading tokenizer...')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_model_name_or_path=model_name_or_path)\n",
        "# default to left padding\n",
        "tokenizer.padding_side = \"left\"\n",
        "# Define PAD Token = EOS Token = 50256\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "# Get the actual model.\n",
        "print('Loading model...')\n",
        "model = GPT2ForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_name_or_path, config=model_config)\n",
        "\n",
        "# resize model embedding to match new tokenizer\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# fix model padding token id\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "# Create data collator to encode text and labels into numbers.\n",
        "gpt2_classificaiton_collator = GPT2ClassificationCollator(use_tokenizer=tokenizer,\n",
        "                                                          labels_encoder=labels_ids,\n",
        "                                                          max_sequence_len=max_length)\n",
        "\n",
        "\n",
        "print('Dealing with Train...')\n",
        "# Create pytorch dataset.\n",
        "train_dataset = TranscriptDataset(path='./dataset_ratings_one/',\n",
        "                                  ratings_file='ratings.csv',\n",
        "                               use_tokenizer=tokenizer)\n",
        "print('Created `train_dataset` with %d examples!'%len(train_dataset))\n",
        "\n",
        "# Move pytorch dataset into dataloader.\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=gpt2_classificaiton_collator)\n",
        "print('Created `train_dataloader` with %d batches!'%len(train_dataloader))\n",
        "\n",
        "print()\n",
        "\n",
        "print('Dealing with Validation...')\n",
        "# Create pytorch dataset.\n",
        "valid_dataset =  TranscriptDataset(path='./dataset_ratings_two/',\n",
        "                                   ratings_file='ratings_round_two.csv',\n",
        "                               use_tokenizer=tokenizer)\n",
        "print('Created `valid_dataset` with %d examples!'%len(valid_dataset))\n",
        "\n",
        "# Move pytorch dataset into dataloader.\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=gpt2_classificaiton_collator)\n",
        "print('Created `eval_dataloader` with %d batches!'%len(valid_dataloader))\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # default is 1e-8.\n",
        "                  )\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "# `train_dataloader` contains batched data so `len(train_dataloader)` gives\n",
        "# us the number of batches.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "all_loss = {'train_loss':[], 'val_loss':[]}\n",
        "all_acc = {'train_acc':[], 'val_acc':[]}"
      ],
      "metadata": {
        "id": "FayfUagHFsvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NOW we run the thing\n",
        "# Get the current date and time\n",
        "current_datetime = datetime.now()\n",
        "\n",
        "# Format it as \"YYYYMMDDHHMMSS\"\n",
        "date_string = current_datetime.strftime(\"%Y%m%d%H%M%S\")\n",
        "# Loop through each epoch.\n",
        "print('Epoch')\n",
        "if not os.path.exists(f'./results/{date_string}'):\n",
        "    os.makedirs(f'./results/{date_string}')\n",
        "results_csv = io.open(f'./results/{date_string}/loss_acc.csv', 'w', encoding=\"utf-8\")\n",
        "results_csv.write(\"train_loss,val_loss,train_acc,valid_acc\")\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print()\n",
        "  print('Training on batches...')\n",
        "  # Perform one full pass over the training set.\n",
        "  train_labels, train_predict, train_loss = train(train_dataloader, optimizer, scheduler, None)\n",
        "  # print(\"train_labels\", train_labels)\n",
        "  # print(\"train predict\", train_predict)\n",
        "  # print(\"train loss\", train_loss)\n",
        "  train_acc = accuracy_score(train_labels, train_predict)\n",
        "  # print(\"train acc\", train_acc)\n",
        "\n",
        "  # Get prediction form model on validation data.\n",
        "  # print('Validation on batches...')\n",
        "  valid_labels, valid_predict, val_loss = validation(valid_dataloader, None)\n",
        "  # print(\"valid_labels\", valid_labels)\n",
        "  # print(\"valid predict\", valid_predict)\n",
        "  # print(\"valid loss\", val_loss)\n",
        "  val_acc = accuracy_score(valid_labels, valid_predict)\n",
        "  # print(\"valid acc\", val_acc)\n",
        "\n",
        "  # Print loss and accuracy values to see how training evolves.\n",
        "  print(\"  train_loss: %.5f - val_loss: %.5f - train_acc: %.5f - valid_acc: %.5f\"%(train_loss, val_loss, train_acc, val_acc))\n",
        "  results_csv.write(f\"{train_loss},{val_loss},{train_acc},{val_acc}\")\n",
        "\n",
        "  # Store the loss value for plotting the learning curve.\n",
        "  all_loss['train_loss'].append(train_loss)\n",
        "  all_loss['val_loss'].append(val_loss)\n",
        "  all_acc['train_acc'].append(train_acc)\n",
        "  all_acc['val_acc'].append(val_acc)\n",
        "\n",
        "results_csv.close()"
      ],
      "metadata": {
        "id": "pEi5zUpLFl1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Plot loss curves.\n",
        "plot_dict(all_loss, use_xlabel='Epochs', use_ylabel='Value', use_linestyles=['-', '--'])\n",
        "\n",
        "# Plot accuracy curves.\n",
        "plot_dict(all_acc, use_xlabel='Epochs', use_ylabel='Value', use_linestyles=['-', '--'])\n",
        "\n",
        "# Get prediction form model on validation data. This is where you should use\n",
        "# your test data.\n",
        "true_labels, predictions_labels, avg_epoch_loss = validation(valid_dataloader, None)\n",
        "\n",
        "# Create the evaluation report.\n",
        "evaluation_report = classification_report(true_labels, predictions_labels, labels=list(labels_ids.values()), target_names=list(labels_ids.keys()))\n",
        "# Show the evaluation report.\n",
        "print(evaluation_report)\n",
        "\n",
        "# Plot confusion matrix.\n",
        "plot_confusion_matrix(y_true=true_labels, y_pred=predictions_labels,\n",
        "                      classes=list(labels_ids.keys()), normalize=True,\n",
        "                      magnify=0.1,\n",
        "                      );\n",
        "'''"
      ],
      "metadata": {
        "id": "o7hmKagQFdfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), f'results/{date_string}/model.pth')"
      ],
      "metadata": {
        "id": "0R8PFKqaFfbE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}